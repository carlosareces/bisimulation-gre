\chapter{Conclusiones}
\label{sec:conclusiones}


En esta tesis se estudi\'o la generaci\'on autom\'atica de expresiones referenciales. Teniendo como meta generar expresiones referenciales como las personas lo har\'ian. Para eso se estudi\'o la generaci\'on humana de expresiones referenciales desde una perspectiva psicoling\"u\'istica concluyendo que el no-determinismo y la sobreespecificaci\'on son puntos claves a tener en cuenta. Tambi\'en aprendimos que no siempre las personas incluyen relaciones cuando es estrictamente necesario, es decir cuando no se puede identificar al target s\'olo con propiedades proposicionales. Vimos el rol importante de la existencia de corpora, que nos permite varias cosas: por un lado aprender qu\'e dir\'ian las personas en distintas situaciones, y usar esos datos para intentar imitar al corpus, y por otro nos permite comparar la salida de los algoritmos con ERs de las personas. Mostramos especificaiones de corpora existente,los clasificamos seg\'un el tipo de ERs que contiene, y los comparamos entre ellos.
Dimos definiciones y vocabulario espec\'ifico del \'area, y estudiamos las diferentes aproximaciones a la soluci\'on. En este proceso vimos que hay varias cosas a tener en cuenta para generar ERs autom\'aticamente: primero es c\'omo y qu\'e representar del modelo, y esto es muy importante ya que puede hacer que nuestro algoritmo genere cosas no deseadas. Segundo como guiar al algoritmo, dependiendo del algoritmo, algunos dan una ER minimal, pero a\'un as\'i pueden generar varias ERs minimales, entonces, cu\'al de ellas elegir?. Vimos que muchos algoritmos usan una lista de preferencias fija de propiedades, otros una funci\'on de costo a minimizar, es decir devuelven la ER de menor costo. En cualquiera de los casos el algoritmo d\'a como mucho una ER, y no tenemos informaci\'on de qu\'e tan buena es esa ER. Conclu\'imos que la generaci\'on de expresiones referenciales es una tarea en la cual hay incertidumbre. 
Entre las aproximaciones estudiadas est\'a la de \cite{areces08} la cu\'al decidimos adaptar. Esta aproximaci\'on usa teor\'ia de modelos, y l\'ogicas para generar ERs, para representar el modelo usa estructuras de kripke, al igual que otros algoritmos d\'a una s\'ola ER de salida y ten\'ia una lista de preferencias de propiedades ordenadas de mayor a menor. Al ser un algoritmo que usa l\'ogica y al ser el algoritmo independiente de la l\'ogica, es decir funciona con la l\'ogica que querramos, estudiamos las distintas l\'ogicas y sus lenguajes asociados, y viendo que clases de f\'ormulas nos ayudar\'ian a generar ERs con la exprevidad que las personas las generan, conclu\'imos que el lenguaje m\'as adecuado a nuestra tarea es \EL. Esta l\'ogica tambi\'en tiene la ventaja de hacer que la realizaci\'on sint\'actica sea menos  complicada que con otras l\'ogicas m\'as expresivas. Reemplazamos esa lista de preferencias por una distribuci\'on finita de probabilidades, las cuales guiar\'an el proceso de inclusi\'on de propiedades unarias y binarias, las cuales son tratadas sin orden de preferencias entre ellas, m\'as que el orden de la probabilidad. Agregamos un componente alestorio, que nos va a permitir al ejecutar el algotmo muchas veces obtener no una sino un ranking de ERs generadas a partir del modelo dado y la distribuci\'on de probabilidades de las palabras del vocabulario. 
El algoritmo va particionando el modelo guiado por la distribuc\'on de probabilidades dada, y refinando las clases, una vez que no puede refinar \'as termina dando como resultado ERs para todos los objetos del modelo, si es posible en la expresividad del lenguaje elegido y con el modelo que le hemos dado como input. El algoritmo es muy efiiente y garantiza encontrar una ER para cada elemento si existe, en tiempo no polinomial no \EL.
Evaluamos nuestra propuesta sobre datos de benchmarks del \'area, comparando con corpora en la medida de lo posible. 
Probamos
el algoritmo propuesto en el corpus GRE3D7 y se encontr\'o que es capaz de generar una gran proporci\'on de las REs sobreespecificadas que se encuentran en el corpus sin generar expresiones referenciales trivialmente redundantes.

\cite{viet:gene11} entren\'o \'arboles de decisi\'on que son capaces de lograr una precisi\'on media del 65\% en el corpus GRE3D7.
El enfoque basado en \'arboles de decisi\'on es capaz de generar descripciones relacionales sobreespecificadas, 
pero que podr\'ian no ser expresiones referenciales.
De hecho, como los \'arboles de decisi\'on no verifican la extensi\'on de la expresi\'on generada m\'as de un modelo de la escena, la
descripci\'on generada podr\'ia no identificar de forma \'unica el objetivo. Como ya hemos comentado,
nuestro algoritmo asegura la terminaci\'on y siempre encuentra una expresi\'on referencial, si existe. Por otra parte, logra un promedio de 75,03 \% de precisi\'on en las escenas utilizadas en nuestras pruebas.

 %comenzamos dando ejemplos e introduciendo vocabulario espec\'ifico del \'area, vemos que no hay un \'unico resultado correcto, lo cual hace la tarea sea m\'as compleja. Cada etapa de la GER tiene un desaf\'io propio, comenzando desde qu\'e y c\'omo representar el contexto, siguiendo por qu\'e teor\'ias usar para mantener la complejidad de la tarea en un nivel aceptable a aplicaciones del mundo real, consiguiendo la expresividad necesaria. Proponemos generar no una, sino un ranking de expresiones referenciales. Adem\'as integramos una distribuci\'on de probabilidades finita para manejar la incertidumbre de la tarea de GER.

%\subsection{Conclusiones de la aproximaci\'on}

%In this article we extend~\cite{areces08} algorithm to generate REs similar to those produced by humans. The modifications 
%proposed are based on two observations. First, it has been argued that no fixed ordering of properties is able to generate all the REs produced by humans and, second, humans frequently overspecify their REs~\cite{Engelhardt_Bailey_Ferreira_2006,arts}. We tested 
%the proposed algorithm on the GRE3D7 corpus and found that it is able to generate a large proportion of the overspecified REs found in the corpus without generating trivially redundant referring expressions.

%\cite{viet:gene11} trains decision trees that are able to achieve a 65\% average accuracy on the GRE3D7 corpus. 
%The approach based on decision trees is able to generate overspecified relational descriptions, but they might fail to be referring 
%expressions. Indeed, as the decision trees does not verify the extension of the generated expression over a model of the scene, the 
%generated descriptions might not uniquely identify the target.  As we have already discussed,
%our algorithm ensures termination and it always finds a referring expression if one exists.  Moreover, it achieves an average of 75.03\% of accuracy over the scenes used in our tests. 

%Different algorithm for the generation of overspecified and distinguishing referring expressions has been proposed in recent years 
%(see, e.g.,~\cite{delucena-paraboni:2008:ENLG,ruud-emiel-mariet:2012:INLG2012}.  But, to our knowledge, they have not been evaluated on the 
%GRE3D7 corpus and, hence, comparison is difficult. \cite{delucena-paraboni:2008:ENLG} and \cite{ruud-emiel-mariet:2012:INLG2012} algorithm
%have been evaluated on the TUNA-AR corpus~\cite{gatt-balz-kow:2008:ENLG} where they have achieved a 33\% and 40\% accuracy respectively. 
%As the TUNA-AR corpus includes only propositional REs, it would be interesting future work to evaluate how these algorithms perform in corpora with relational REs such as GRE3D7. 

%A second theme worth discussing is how our algorithm deals with overspecification. As we described in Section~\ref{sec:overspecification} the generation of overspecified REs is performed in two steps. In the first iteration, the probability of including a property in the RE depends only on its \puse. It does not matter whether the property actually eliminate any distractor; hence, the resulting RE may be overspecified. After all properties had a chance of being included this way, if the resulting RE is not distinguishing, then the algorithm enters a second phase in which it makes sure that the RE identifies the target uniquely.  This model is inspired by the work of~\cite{keysar:Curr98} on egocentrism and natural language production.  Keysar~et al.\ put forwards the proposal that when producing language, considering the hearers point of view is not done from the outset but it is rather an afterthought~\cite{keysar:Curr98}. They argue that adult speakers produce REs egocentrically, just like children do, but then adjust the REs so that the addressee is able to identify the target unequivocally. The first, egocentric, step is a heuristic process based in a model of saliency of the scene that contains the target. 

%Our definition of \puse\ is intended to capture the saliences of the properties for different scenes and targets. The \puse\ of a property changes according to the scene as we discussed in Section~\ref{subsec:learning}. This is in contrast with previous work where the saliency of a property is constant in a domain. Keysar et al.~argue that the reason for generate-and-adjust procedure may have to do with information processing limitations of the mind:if the heuristic that guides the egocentric phase is well tunned, it succeeds with a suitable RE in most cases and seldom requires adjustments. Interestingly, we observe a similar behavior with our algorithm:when \puse\ values learn from the domain are used, the algorithm is not only much more accurate but also much faster. 

%As future work we plan to evaluate our algorithm on more complex domains like those provided by Open Domain Folksonimies~\cite{pacheco-duboue-dominguez:2012:NAACL-HLT}. We also plan to explore corpora obtain from interaction, such as the GIVE Corpus~\cite{GarGarKolStr10} where it it is common to observe multi shot REs. Under time pressure subjects will first produce an underspecified expression that includes salient properties of the target (e.g., ``the red button'').  And then, in a following utterance, they add additional properties (e.g., ``to the left of the lamp'') to make the expression a proper RE  identifying the target uniquely.

%En esta tesis extendimos el algoritmo~\cite{areces08} para generar ER similares a las producidas por los humanos. Las modificaciones propuestas se basan en dos observaciones. En primer lugar, se ha argumentado que hay orden fijo de propiedades que es capaz de generar todas las ER producidas por los seres humanos y, en segundo lugar vimos que los seres humanos con frecuencia sobreespecifican sus ER\cite{Engelhardt_Bailey_Ferreira_2006, arts}. 


Algoritmos diferentes para la generaci\'on de expresiones referenciales sobreespecificadas y distintivas se ha propuesto en los \'ultimos a\~nos
(Ver, por ejemplo,~\cite{delucena-paraboni:2008:ENLG, ruud-emiel-mariet:2012:INLG2012}). Pero, hasta donde sabemos, no han sido evaluados en el
GRE3D7 corpus y, por lo tanto, la comparaci\'on es difícil.  \cite{delucena-paraboni:2008:ENLG} y \cite{ruud-emiel-mariet:2012:INLG2012}
 algoritmo
han sido evaluados en el corpus TUNA-AR~\cite{gatt-balz-kow:2008:ENLG} han logrado una precisi\'on de 33 \% y 40 \% respectivamente.
Como el corpus TUNA-AR s\'olo incluye ER proposicionales, sería interesante el trabajo futuro para evaluar c\'omo estos algoritmos realizan en corpora con ER relacionales como GRE3D7.

Un segundo tema vale la pena discutir es c\'omo nuestro algoritmo con sobreespecificaci\'on funciona. Como describimos en la Secci\'on~\ref{sec:overspecification} la generaci\'on de ER sobreespecificadas se realiza en dos pasos. En la primera iteraci\'on, la probabilidad de incluir una propiedad en la ER depende s\'olo de su \puse. No importa si la propiedad en realidad elimina cualquier distractor; Por lo tanto, la ER resultante puede ser sobreespecificada. Despu\'es de todas las propiedades tuvieron la oportunidad de ser inclu\'idas de esta manera, si la ER resultante no identifica al target un\'ivocamente, entonces el algoritmo entra en una segunda fase en la que se asegura que la ER identifica el objetivo un\'ivocamente. Este modelo est\'a inspirado en la obra de~\cite{keysar:Curr98} en el egocentrismo y el lenguaje natural de producci\'on. Keysar~et. al dijeron que al producir el lenguaje, tener en cuenta el punto de vista de los oyentes no se hace desde el principio, es m\'as bien una idea de \'ultimo momento~\cite{keysar:Curr98}. Argumentan que los hablantes adultos producen ERs egoc\'entricamente, al igual que hacen los ni\~nos, pero luego ajustan las ERs para que el destinatario sea capaz de identificar al target de forma un\'ivoca. El primer paso es egoc\'entrico, es un proceso heur\'istico basado en un modelo de la prominencia de la escena que contiene el target.

Nuestra definici\'on de \puse\ pretende capturar las prominencias de las propiedades de diferentes escenas y objetivos. El \puse\ de una propiedad cambia de acuerdo a la escena como discutimos en la Secci\'on~\ref{sec:learning}. Esto est\'a en contraste con el trabajo anterior, donde el prominencia de una propiedad es constante en un dominio. Keysar et al~argumentan que la raz\'on del procemiento de generar y ajustar puede tener que ver con las limitaciones de procesamiento de informaci\'on de la mente:. Si la heur\'istica que gu\'ia la fase egoc\'entrica est\'a bien sintonizada, tiene \'exito en e lprimer intento, siendo la primer ER adecuada en la mayor\'ia de los casos y rara vez requiere ajustes. Curiosamente, se observa un comportamiento similar con nuestro algoritmo: cuando los valores de \puse\ se aprenden del dominio en que se van a utilizar, el algoritmo no s\'olo es mucho m\'as preciso, pero tambi\'en mucho m\'as r\'apido.

Se cre\'o conjuntamente con la Universidad de Sao Paulo, el ZOOM compus de expresiones referenciales de puntos de inter\'es en mapas. Este corpus esta en prceso de revisi\'on y ser\'a liberado para investigaci\'on pronto. Sobre mapas de este corpus se realizaron 3 casos de estudio, vea Secci\'on \ref{sec:caso_estudio} del Cap\'itulo \ref{sec:corpus}. El caso de estudio si bien muestra que el algoritmo es capaz de generar ERs en domimnios tan naturales de la vida real, como son los mapas de ciudades, tambi\'en dej\'o al descubierto algunas cuestiones l\'ogicas que podr\'ian ser mejoradas en trabajo futuro. En el caso particular de la prueba con target plural, nos muestra que todav\'ia queda mucho por hacer.

Como trabajo futuro tambi\'en tenemos la intenci\'on de evaluar nuestro algoritmo de dominios m\'as complejos como los de dominio abiertos proporcionados en Folksonimies~\cite{pacheco-duboue-dominguez:2012:NAACL-HLT}. Los corpus Stars/2 recientemente liberados, ser\'ian interesantes para evaluar el algoritmo, ya que poseen situaciones complejas de referencia que hacen amplio uso de relaciones y expresiones de hasta tres landmarks. Tambi\'en planeamos explorar corpus que se obtienen de la interacci\'on humana, como el DAR Corpus~\cite{GarGarKolStr10} donde es com\'un observar ERs en varios intentos, es decir dando expresiones parciales en cada intento. Bajo presi\'on de tiempo los hablantes producen primero una expresi\'on under-especificada que incluye las propiedades m\'as destacadas del target (por ejemplo, ``el bot\'on rojo''). Y luego, en un siguiente enunciado, a\~naden propiedades adicionales (por ejemplo, ``a la izquierda de la l\'ampara'') para que la expresi\'on sea una ER adecuada para identificar de manera \'unica al target.

Un potencial interesante del algoritmo, es que puede dar ERs para todos los objetos, dej\'andonos como trabajoj futuro una evaluaci\'on intensiva del funciomaniento para la generaci\'on de plurales. 
