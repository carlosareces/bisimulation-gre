\chapter{Conclusiones y Trabajo Futuro}
\label{sec:conclusiones}

El concepto te\'orico y filos\'ofico de referencia a un objeto del mundo real ha sido y continúa siendo objetivo de amplio debate~\cite{searle69,abbott16}. Dada su relevancia para el funcionamiento del lenguaje natural, el concepto pr\'actico y aplicado de referencia es uno de los temas m\'as estudiados en el \'area de generaci\'on autom\'atica de lenguaje natural. Esta tesis se enmarca en el \'area de generaci\'on autom\'atica de expresiones referenciales (GER), que es un \'area m\'as reciente que su contraparte filos\'ofica pero también prol\'ifera. \cite[pag.~174]{survey} definen como sigue la tarea en la que se enmarca esta tesis de la siguiente manera. 


\begin{itshape}
La tarea de selecci\'on de contenido (para la generaci\'on autom\'atica de expresiones referenciales) es un proceso de balanceo complejo: Debemos decir lo suficiente como para permitir la identificaci\'on del referente, pero no demasiado. Una selecci\'on de informaci\'on debe hacerse, y debe hacerse r\'apido. 
\end{itshape}

Esta definici\'on de la tarea tiene en cuenta dos aspectos centrales considerados en esta tesis. Primero, reconoce que la tarea involucra una selecci\'on de informaci\'on de forma de que el referente se identifique un\'ivocamente. Esta tesis aborda esta cuesti\'on con una soluci\'on que combina probabilidades aprendidas del dominio que funcionan como heur\'istica a la hora de seleccionar la informaci\'on y la noci\'on l\'ogica de similaridad para asegurar unicidad. Segundo, la definici\'on dice que la selecci\'on de informaci\'on debe hacerse r\'apido. Esta tesis aborda esta cuesti\'on a trav\'es de la noci\'on l\'ogica de simulaciones y los algoritmos conocidos eficientes para resolver esta tarea para lenguajes l\'ogicos de distintas expresividades. 

El \'area de GER comienza a activarse en los años 80 con el creciente interés en el Procesamiento Autom\'atico de Lenguaje Natural~\cite{appelt85,appelt87}. Desde entonces ha avanzado a través de investigaciones independientes y de desaf\'ios de evaluaci\'on como el TUNA~\cite{gatt-balz-kow:2008:ENLG,gatt09}, GREC~\cite{belz08,belz10}, y GIVE~\cite{give-overview-09,give2-inlg-report}. Estos desaf\'ios han permitido la comparaci\'on de algoritmos del estado del arte, pero se restringen a dominios simplificados y poco realistas como se argumenta en~\cite{survey}. Esta tesis intenta avanzar el estado del arte ante el desaf\'io de dominios m\'as complejos y realistas que necesariamente traen consigo nuevas fuentes de incertidumbre.     

A continuaci\'on se resumen los principales aportes de esta tesis al \'area de Generaci\'on Autom\'atica de Expresiones Referenciales en contextos con incertidumbre. Y luego se discuten nuevas \'areas de investigaci\'on que desaf\'ian los l\'imites de los enfoques actuales. 

\section{Conclusiones}

En esta tesis investigamos la generaci\'on autom\'atica de rankings de expresiones referenciales en contextos con incertidumbre. Las posibles aplicaciones de la generaci\'on de expresiones referenciales que deben referirse al mundo real (e.g. software para robots, sistemas gps, etc) sufren de incertidumbre por datos ruidosos de sensores y modelos incompletos de la realidad. Extendimos técnicas y algoritmos
de teor\'ia de modelos y simulaciones integrando una distribuci\'on finita de probabilidades que representa esta incertidumbre. Nuestro objetivo es generar un ranking de las expresiones referenciales ordenado por la
probabilidad de ser correctamente interpretada en el contexto. 

A continuaci\'on resumimos nuestros aportes organizados en 4 temas. En primer lugar, describimos nuestras contribuciones con respecto al desarrollo de técnicas y de algoritmos de generaci\'on de expresiones referenciales que extienden algoritmos cl\'asicos de minimizaci\'on de aut\'omatas aplicados a la caracterizaci\'on de modelos de primer orden. Luego, reflexionamos sobre c\'omo dichos algoritmos fueron extendidos usando probabilidades aprendidas de corpora con técnicas de aprendizaje autom\'atico y mencionamos las limitaciones de este enfoque. Adem\'as, resumimos lo que aprendimos al evaluar los algoritmos resultantes usando
técnicas autom\'aticas y evaluaciones de jueces humanos sobre datos de benchmarks del \'area. Finalmente, explicamos nuestros resultados en el proceso de recolecci\'on y evaluaci\'on de un nuevo corpus de expresiones referenciales de puntos de interés en mapas de ciudades con distintos niveles de zoom, el cual es relevante a aplicaciones sobre mapas del mundo real.


\subsection{Extendiendo Algoritmos de Simulaciones con Probabilidades}

%algoritmo probabilisitico
Entre las aproximaciones a la GER est\'a la de \cite{areces08}, la cu\'al decidimos tomar como punto de partida por la generalidad que nos da la teor\'ia de modelos permitiéndonos elegir un buen balance entre la expresividad del lenguaje l\'ogico a utilizar y la complejidad computacional de los algoritmos de GER. Siguiendo este trabajo previo usamos teor\'ia de modelos, y lenguajes l\'ogicos para generar ERs, y para representar el modelo usamos estructuras de kripke. 

El enfoque basado en teor\'ia de modelos de esta tesis trabaja a nivel sem\'antico y no sint\'actico. Esto permite proponer algoritmos genéricos para la GER que son parametrizables para distintos lenguajes l\'ogicos con distinta expresividad. En este sentido los algoritmos propuestos son independientes del lenguaje l\'ogico elegido, es decir funcionan con el lenguaje l\'ogico que querramos. En esta tesis describimos las distintas l\'ogicas usadas para la GER, y analizamos qu\'e clases de f\'ormulas nos ayudar\'ian a generar ERs con la expresividad que las personas las generan. Decidimos, en el Cap\'itulo~\ref{sec:intro_logica}, que el lenguaje m\'as adecuado para los dominios que quer\'iamos modelar era \EL. Esta l\'ogica tambi\'en tiene la ventaja de hacer que la realizaci\'on sint\'actica sea menos  complicada que con otras l\'ogicas m\'as expresivas. 

El algoritmo original propuesto por \cite{areces08}, al igual que otros algoritmos del \'area, da una s\'ola ER de salida y tiene una lista de preferencias de propiedades ordenada. En esta tesis propusimos c\'omo reemplazar esa lista de preferencias por una distribuci\'on finita de probabilidades, las cuales gu\'ian el proceso de inclusi\'on de propiedades unarias y binarias. Agregamos al algoritmo un componente aleatorio, que nos permite ejecutar el algoritmo muchas veces y obtener no una sino un ranking de ERs generadas a partir del modelo dado y la distribuci\'on de probabilidades de las palabras del vocabulario. 

%algoritmo probabilisitico
El algoritmo va particionando el modelo guiado por la distribuci\'on de probabilidades, y refinando las clases, una vez que no puede refinar m\'as termina dando como resultado ERs para todos los objetos del modelo, si es posible en la expresividad del lenguaje elegido y con el modelo que le hemos dado como input. El algoritmo es muy eficiente y garantiza encontrar una ER para cada elemento si existe, en tiempo polinomial para \EL.


\subsection{Probabilidades de Uso y Sobreespecificaci\'on}

Un segundo tema que vale la pena discutir es c\'omo nuestro algoritmo con sobreespecificaci\'on funciona. Como describimos en la Secci\'on~\ref{sec:overspecification} la generaci\'on de ERs sobreespecificadas se realiza en dos pasos. En la primera iteraci\'on, la probabilidad de incluir una propiedad en la ER depende s\'olo de su probabilidad de uso. No importa si la propiedad en realidad elimina cualquier distractor. Por lo tanto, la ER resultante puede ser sobreespecificada. Despu\'es de que todas las propiedades tuvieron la oportunidad de ser inclu\'idas de esta manera, si la ER resultante no identifica al target un\'ivocamente, entonces el algoritmo entra en una segunda fase en la que se asegura que la ER identifica al target un\'ivocamente. Este modelo est\'a inspirado en la obra de~\cite{keysar:Curr98} de producci\'on de lenguaje natural y egocentrismo. Keysar~et al argumentan que, al producir el lenguaje, el hecho de tener en cuenta el punto de vista de los oyentes no se hace desde el principio, es m\'as bien un ajuste de \'ultimo momento~\cite{keysar:Curr98}. En su modelo cognitivo de producci\'on del lenguaje los hablantes adultos producen ERs egoc\'entricamente, al igual que hacen los ni\~nos, pero luego ajustan las ERs para que el destinatario sea capaz de identificar al target de forma un\'ivoca. El primer paso es egoc\'entrico, es un proceso heur\'istico basado en un modelo de la \textbf{prominencia} de las propiedades de la escena que contiene el target.

%probabilidades de uso
Nuestra definici\'on de probabilidad de uso \puse\ pretende capturar las \textbf{prominencias}\footnote{Del ingl\'es \emph{saliency}.} de las propiedades de diferentes escenas y objetivos. El \puse\ de una propiedad cambia de acuerdo a la escena como discutimos en la Secci\'on~\ref{sec:learning}. Esto est\'a en contraste con el trabajo anterior, donde el prominencia de una propiedad se asume constante en un dominio. Keysar et al~argumentan que la raz\'on del procedimiento de generar y ajustar puede tener que ver con las limitaciones de procesamiento de informaci\'on de la mente. Si la heur\'istica que gu\'ia la fase egoc\'entrica est\'a bien sintonizada, tiene \'exito en el primer intento, siendo la primer ER adecuada en la mayor\'ia de los casos y rara vez requiere ajustes. Es intesante observar que un comportamiento similar se obtiene con nuestro algoritmo: cuando los valores de \puse\ se aprenden del dominio en que se van a utilizar, el algoritmo es mucho m\'as preciso y mucho m\'as r\'apido.


\subsection{Desaf\'ios en la Evaluaci\'on de Sistemas de Generaci\'on}

%corpora y evaluaci\'on
En esta tesis se estudi\'o la generaci\'on autom\'atica de expresiones referenciales teniendo como meta generar expresiones referenciales como las personas lo har\'ian. Para eso se estudi\'o la generaci\'on humana de expresiones referenciales desde una perspectiva psicoling\"u\'istica concluyendo que el no-determinismo y la sobreespecificaci\'on son puntos claves a tener en cuenta. Tambi\'en aprendimos que no siempre las personas incluyen relaciones cuando es estrictamente necesario, es decir cuando no se puede identificar al target s\'olo con propiedades proposicionales. Vimos el rol importante de la existencia de corpora, que nos permite varias cosas: por un lado aprender qu\'e dir\'ian las personas en distintas situaciones, y usar esos datos para intentar imitar al corpus, y por otro nos permite comparar la salida de los algoritmos con ERs de las personas. Mostramos especificaciones de corpora existente, los clasificamos seg\'un el tipo de ERs que contiene, y los comparamos entre ellos.

%algoritmos y evaluaci\'on
Dimos definiciones y vocabulario espec\'ifico del \'area, y estudiamos las diferentes aproximaciones a la soluci\'on. En este proceso vimos que hay varias cosas a tener en cuenta para generar ERs autom\'aticamente: primero es c\'omo y qu\'e representar del modelo, y esto es muy importante ya que puede hacer que nuestro algoritmo genere cosas no deseadas. Segundo como guiar al algoritmo, dependiendo del algoritmo, algunos dan una ER minimal, pero a\'un as\'i pueden generar varias ERs minimales, entonces, cu\'al de ellas elegir?. Vimos que muchos algoritmos usan una lista de preferencias fija de propiedades, otros una funci\'on de costo a minimizar, es decir devuelven la ER de menor costo. En cualquiera de los casos el algoritmo da como mucho una ER, y no tenemos informaci\'on de qu\'e tan buena es esa ER. Conclu\'imos que la generaci\'on de expresiones referenciales es una tarea en la cual hay incertidumbre. 

%evaluacion
Evaluamos nuestra propuesta sobre datos de benchmarks del \'area, comparando con corpora en la medida de lo posible. Probamos el algoritmo propuesto en el corpus GRE3D7 y se encontr\'o que es capaz de generar una gran proporci\'on de las ERs sobreespecificadas que se encuentran en el corpus sin generar expresiones referenciales trivialmente redundantes.

%evaluacion
\cite{viet:gene11} entren\'o \'arboles de decisi\'on que son capaces de lograr una precisi\'on media del 65\% en el corpus GRE3D7.
El enfoque basado en \'arboles de decisi\'on es capaz de generar descripciones relacionales sobreespecificadas, 
pero que podr\'ian no ser expresiones referenciales.
De hecho, como los \'arboles de decisi\'on no verifican la extensi\'on de la expresi\'on generada en el modelo de la escena, la
descripci\'on generada podr\'ia no identificar de forma \'unica el objetivo. Como ya hemos comentado,
nuestro algoritmo asegura la terminaci\'on y siempre encuentra una expresi\'on referencial, si existe. Por otra parte, logra un promedio de 75,03 \% de precisi\'on en las escenas utilizadas en nuestras pruebas.

%evaluacion
Algoritmos diferentes para la generaci\'on de expresiones referenciales sobreespecificadas y distintivas se ha propuesto en los \'ultimos a\~nos (ver, por ejemplo,~\cite{delucena-paraboni:2008:ENLG,ruud-emiel-mariet:2012:INLG2012}). Pero, hasta donde sabemos, no han sido evaluados en el
GRE3D7 corpus y, por lo tanto, la comparaci\'on es dif\'icil. Los algoritmos de \cite{delucena-paraboni:2008:ENLG} y \cite{ruud-emiel-mariet:2012:INLG2012} han sido evaluados en el corpus TUNA-AR~\cite{gatt-balz-kow:2008:ENLG} han logrado una precisi\'on de 33 \% y 40 \% respectivamente.
Como el corpus TUNA-AR s\'olo incluye ERs proposicionales, ser\'ia interesante evaluar la performance de estos algoritmos en corpora con ERs relacionales como el GRE3D7.


\subsection{Generaci\'on sobre un Contexto del Mundo Real}

%mundo real
Se cre\'o conjuntamente con la Universidad de S\~ao Paulo, el ZOOM corpus de expresiones referenciales de puntos de inter\'es en mapas. Este corpus est\'a en proceso de revisi\'on y ser\'a liberado para investigaci\'on en los pr\'oximos meses. El proceso de recolecci\'on de este corpus demostr\'o ser complejo, esto se vi\'o por ejemplo ya que muchas de las descripciones recolectadas debieron ser descartadas por no ser expresiones referenciales. Adem\'as el corpus mostr\'o tener un porcentaje de expresiones subespecificadas mucho mayor que corpus anteriores recolectados sobre dominios m\'as simples. 

Sobre mapas de este corpus se realizaron 3 casos de estudio que se describen en el Cap\'itulo \ref{sec:corpus}. Estos casos de estudio, si bien muestran que el algoritmo es capaz de generar ERs en dominios naturales de la vida real, como son los mapas de ciudades, tambi\'en dej\'o al descubierto algunas cuestiones l\'ogicas que podr\'ian ser mejoradas en trabajo futuro. En el caso particular de la GER con target plural, nos muestra que todav\'ia queda mucho por hacer.


\section{Trabajo Futuro}

En esta secci\'on describimos cuatro l\'ineas de trabajo claras en las que los aportes de esta tesis podr\'ian ser continuados. Algunas de estas \'areas han sido previamente estudiadas pero a\'un plantean muchos desaf\'ios, como la generaci\'on de ERs plurales y generaci\'on de ERs de forma incremental en entornos interactivos. Otros temas como el uso de lenguajes l\'ogicos modales m\'as expresivos y la inclusi\'on de una teor\'ia del dominio son extensiones naturales del enfoque a la GER adoptado en esta tesis que no han sido estudiados previamente. 

\subsection{Interactividad e Incrementalidad}

Estudios previos~\cite{jordan05,gupta05} sugieren que los algoritmos del estado del arte de GER que usan un orden fijo de las propiedades del contexto no se pueden aplicar de forma directa en aplicaciones interactivas. Estos estudios encontraron que en este tipo de aplicaciones los algoritmos del estado del arte se desempeñan peor que estrategias basadas en patrones sencillos y que prestan atenci\'on al historial de la interacci\'on. Un experimento realizado sobre el corpus iMap~\cite{viethendaleguhe11} confirm\'o la importancia de modelar el terreno com\'un de una interacci\'on para producir ERs \'utiles. El trabajo publicado en \cite{stoia06} de GER en entornos de interacci\'on situada en in videojuego hace evidente la necesidad de variar el orden de las propiedades utilizado por los algoritmos dependiendo de caracter\'isticas del contexto que se modifican continuamente (como la distancia a los objetos target y distractores). Nuestro algoritmo, al proveer una distribuci\'on finita de probabilidades asociada a cada propiedad en lugar de requerir un orden fijo, permite un mayor control y dinamismo a la hora de elegir propiedades para una ER en un contexto cambiante. Ser\'ia interesante evaluar su desempeño en este tipo de aplicaciones interactivas. 

%modelos que cambian
Modelos que cambian parcialmente como sucede con los mapas con distintos niveles de ZOOM en el corpus son comunes en aplicaciones interactivas donde el usuario est\'a navegando la aplicaci\'on. En estos dominios el contexto de referencia puede cambiar en su estructura o en el número de objetos y propiedades, mientras algunas caracter\'isticas del contexto se mantienen. El desaf\'io de los algoritmos de GER ser\'ia producir ERs sin empezar desde cero cada vez que el modelo cambia. Algoritmos como el nuestro que se basan en particiones locales del contexto podr\'ian tener una ventaja en este sentido, esta es una l\'inea interesante de trabajo futuro. 
 
%interactividad
Como trabajo futuro tambi\'en tenemos la intenci\'on de evaluar nuestro algoritmo de dominios m\'as complejos como los de dominio abiertos proporcionados en Folksonimies~\cite{pacheco-duboue-dominguez:2012:NAACL-HLT}. Los corpus Stars/2 recientemente liberados, ser\'ian interesantes para evaluar el algoritmo, ya que poseen situaciones complejas de referencia que hacen amplio uso de relaciones y expresiones de hasta tres landmarks. Tambi\'en planeamos explorar corpus que se obtienen de la interacci\'on humana, como el GIVE Corpus~\cite{GarGarKolStr10} donde es com\'un observar ERs en varios intentos, es decir dando expresiones parciales en cada intento. Bajo presi\'on de tiempo los hablantes producen primero una expresi\'on subespecificada que incluye las propiedades m\'as destacadas del target (por ejemplo, ``el bot\'on rojo''). Y luego, en un siguiente enunciado, a\~naden propiedades adicionales (por ejemplo, ``a la izquierda de la l\'ampara'') para que la expresi\'on sea una ER adecuada para identificar de manera \'unica al target. Algoritmos para generar este tipo de ERs han sido propuestos en \cite{denis10}. 


\subsection{Plurales: De Targets Singleton a Conjuntos}

%plurales
Un potencial interesante de nuestros algoritmos que se basan en dividir el modelo a trav\'es de la sem\'antica, es que, en principio puede dar ERs para un conjunto target que no sea singleton. En el Cap\'itulo~\ref{sec:caso_estudio} se presenta un caso de estudio de la generaci\'on de expresiones referenciales plurales pero a\'un no hemos abordado varias cuestiones relacionadas a este tema señaladas por trabajo previo. 

En particular, las expresiones referenciales generadas por nuestro algoritmo tienden a ser largas y conjuntivas cuando en realidad existen expresiones plurales colectivas que ser\'ian m\'as efectivas. En trabajo previo se ha sugerido el uso de disyunci\'on en el lenguaje l\'ogico usado para la generaci\'on~\cite{gardent,gatt07,khan08}.   


\subsection{Lenguajes m\'as Expresivos: Negaci\'on y Probabilidades}

En esta tesis utilizamos principalmente el lenguaje l\'ogico \EL. Es decir sin ning\'un tipo de negaci\'on. Esto mostr\'o ser apropiado para dominios est\'aticos y no agentivos en los que trabajamos. Ser\'ia interesante investigar si para otros dominios ser\'ia \'util tener alg\'un tipo de negaci\'on en el lenguaje. 

En esta tesis la combinaci\'on de l\'ogica y probabilidades se realiza a nivel algor\'itmico. Recientemente se han comenzado a investigar  sem\'antica probabil\'istica para l\'ogica modal~\cite{lando12}. Ser\'ia interesante investigar si incluir probabilidades en la misma sem\'antica de la l\'ogica mejorar\'ia el desempeño de la GER.


\subsection{Razonando con una Teor\'ia del Dominio}


En el Cap\'itulo~\ref{sec:intro} discutimos que todos los modelos son incompletos, especificarlos y tratar de completarlos todo lo posible es un trabajo muy laborioso. Esto puede hacerse m\'as f\'acil si fuera posible escribir axiomas del dominio que ayuden a extender los modelos autom\'aticamente. Por ejemplo, si sabemos que el objeto \emph{e1} est\'a a la derecha del objeto \emph{e2} y el objeto \emph{e2} est\'a a la derecha del objeto \emph{e3}, se puede especificar un axioma en algún framework de especificaci\'on de conocimiento y razonamiento que autom\'aticamente agregue que \emph{e1} est\'a a la derecha del objeto \emph{e3} simplemente diciendo que la relaci\'on a la derecha de es transitiva. 

Existen diversos frameworks para especificar teor\'ias de dominios de este tipo. Uno de los m\'as difundidos son las l\'ogicas para la descripci\'on~\cite{baader03}. Nuestro enfoque a la GER se presta especialmente para la integraci\'on de teor\'ias de dominio dado que se basa en este tipo de l\'ogicas. En particular, nuestros algoritmos generan expresiones referenciales estructuralmente complejas como las que se ilustran en el Cap\'itulo \ref{sec:corpus} y en el Apendice~\ref{er-mapa-zoom}. Ser\'ia interesante evaluar emp\'iricamente si la complejidad de estas f\'ormulas es apropiada para la tarea de GER y definir as\'i c\'omo es apropiado restringir el lenguaje l\'ogico a utilizar en esta tarea. 



