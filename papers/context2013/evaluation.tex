\section{Evaluation} \label{sec:automaticeval}

We perform a automatic evaluation with the metrics given by~\cite{} in the ASGRE-challenge obtainnig the following results.

A comparative evaluation for the TUNA-corpus. 
Using \puse learned as described in Section~\ref{sec:learning} and running our algorithm 100 times we adquire the following results:
About the evaluation method 
In the evaluation results reported below, we use the intrinsic methods used in the ASGRE Challenge. Minimality, defined as the proportion of descriptions produced by a system
that are maximally brief, as per the original definition in Dale (1989). The Dice coefficient, used to compare the description produced by
a system to the human-produced description on the same input domain. %Dice is estimated
MASI, a version of the Jaccard similarity coefficient proposed
by Passonneau (2006) which multiplies the similarity value by a monotonicity coefficient, biasing
the measure towards those cases where DS and
DH have an empty set difference. Intuitively, this
means that those system-produced descriptions are
preferred which do not include attributes that are
omitted by a human. Thus, two of our intrinsic measures assess Humanlikeness (Dice and MASI), while
Minimality reflects the extent to which an algorithm
conforms to brevity, one of the principles that has
emerged from the ASGRE literature.}
We also did another comparison taking into account the 20 first RE that the system produced named SIS\_Furniture\_20 and SIS\_People\_20 in table~\ref{Tabla_sis_1_20}, and when in those 20 is the given for a human we choise this one, we obtain the following results:

\begin{table}[h!]
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
%Figure & Model \puse &  Learning \puse & Random \puse &  Uniform \puse \\
	& DICE	&	MASI	&	A\_ACCURACY	&	UNIQUENESS	&	MINIMALITY	\\
\hline
Furniture	&	0,79\%	&	0,58\%	&	0,43\%	&	0,48\%	&	0,0125\%	\\
People	&	0,65\%	&	0,37\%	&	0,19\%	&	1\%	&	0,0\%	\\

\hline

SIS\_Furniture\_20	&	0,87\%	&	0,7525\%	&	0,65\%	&	0,4625\%	&	0,0125\%	\\
SIS\_People\_20	&	0,81\%	&	0,68\%	&	0,60\%	&	0,97\%	&	0,0147\%	\\
\hline
\end{tabular}
\caption{Percentage average adquired for Furniture and People}
\label{Tabla_sis_1_20}
\end{center}
\end{table}

\section{Human evaluation} \label{sec:evaluation}

We aisle the RE that our system gives another RE that not coincides with the one given by a human in the corpus, and with those realize a human evaluation in order to see if the RE produced by the system are prefered by human than the RE produced by humans. Two judges were asked by each pair of RE.

We have 43 pictures of furniture (from 80) and 55 pictures of people (from 68), for wach of them we manually realize the referring expressions (including the properties given as results by our algorithm) and ask people to evaluate which one is a RE it is that univocally identifies the target object and wich one is better in sense that will be more usefull for a human who is not seeing the red box to identify the object. For do it we prepare a webpage with each of the pictures and 2 choices randomly ordered human and system RE. Out goal is to try to show if RE produced by our system are at less as good as the produced by human, and also we will show that they are even better.

%\begin{table}[h!]
%\begin{center}
%\begin{tabular}{|c|c|c|c|}
%\hline
%           & Agree in & Not agree & Total\\
%\hline 
%Furniture & 25       & 18        & 43 \\
%People    & 25       & 30        & 55 \\
%Total     & 50       & 48        & 98 \\
%\hline
%\end{tabular}
%\caption{Agree between judges} 
%\label{agree-judges}
%\end{center}
%\end{table}

%esta tabla no ayuda...no se que decir, no se como justificar que no coincidan...
%In the Table~\ref{agree-judges} we can see that the both judges choice the same RE 25 times for Furniture and 25 times for People, 

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Judge    & Human choice & System choice & Total\\
\hline 
Judge1 & 10       & 33        & 43 \\
Judge2    & 11       & 32        & 43 \\
\hline
\end{tabular}
\caption{System versus human selected choice for Furniture} 
\label{system-versus-human-furniture}
\end{center}
\end{table}

In the Table~\ref{system-versus-human-furniture} you can see the judges selected the RE generated by our system the 76\% of times in the case of pictures of furnitures.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Judge    & Human choice & System choice & Total\\
\hline 
Judge1 & 25       & 30        & 55 \\
Judge2    & 23       & 32        & 55 \\
\hline
\end{tabular}
\caption{System versus human selected choice for People} 
\label{system-versus-human-people}
\end{center}
\end{table}

In the case of pictures of people you can see in the Table~\ref{system-versus-human-people} that the judges selected more RE generated by our system but the diference in not very significant.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
           & System & System \% & Human & Human \% & Total\\
\hline
Furniture & 23  & 0.92 &  2 & 0.08  & 25 \\
People    & 16  & 0.64 & 9  & 0.36 & 25 \\
Total     & 39  & 0.78    & 11 & 0.22 & 50  \\
\hline
\end{tabular}
\caption{Coincidences between judges, the system is the prefered the 78\% of times} 
\label{system-better}
\end{center}
\end{table}

Taking account just the coincidences between jugdes in average as you can see in the Table~\ref{system-better} they prefered the system in 78\% of times.

Sometimes comparison was unfair because human gives a RE that includes relation that were not annotated so, the system haven't the posibility of produce them. A point in favor of the system is that sometimes the human did an underespecified RE and the system has a better one.\\


